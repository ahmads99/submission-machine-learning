# -*- coding: utf-8 -*-
"""machine-learning-pemula.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16kAfKYP1ITI0tgi2t3RU7_0MkUncSw9Z

# **Proyek Machine Learning: Rock Paper Scissors**
### benzodiahmad@dicoding.org
**Ahmad Attoriq**

1.   Machine Learning
2.   Python

### Dicoding Academy batch 5
"""

!pip install wget

import numpy as np
import wget
import zipfile
from sklearn.model_selection import train_test_split
import tensorflow as tf
import keras
from keras.models import Sequential
from keras.layers import Conv2D, AveragePooling2D, Flatten, Dense, Dropout
from keras.preprocessing import image
from keras.preprocessing.image import ImageDataGenerator
from keras.optimizers import RMSprop
# from keras.losses import CategoricalCrossentropy
from IPython.display import Image
from google.colab import files

url = "https://github.com/dicodingacademy/assets/releases/download/release/rockpaperscissors.zip"
wget.download(url, 'rockpaperscissors.zip')

with zipfile.ZipFile('rockpaperscissors.zip', 'r') as zip_ref:
    zip_ref.extractall('/content/dataset')

train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    # width_shift_range=0.2,
    # height_shift_range=0.2,
    # shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    validation_split=0.4
)

val_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    # width_shift_range=0.2,
    # height_shift_range=0.2,
    # shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    validation_split=0.4
)

train_generator = train_datagen.flow_from_directory(
    '/content/dataset/rockpaperscissors/rps-cv-images',
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical',
    subset='training'
)

validation_generator = val_datagen.flow_from_directory(
    '/content/dataset/rockpaperscissors/rps-cv-images',
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical',
    subset='validation'
)

model = Sequential([
    Conv2D(32, (3,3), activation='relu', input_shape=(224, 224, 3)),
    AveragePooling2D(2,2),
    Conv2D(64, (3,3), activation='relu'),
    AveragePooling2D(2,2),
    # Conv2D(256, (3,3), activation='relu'),
    # AveragePooling2D(2,2),
    Conv2D(64, (3,3), activation='relu'),
    AveragePooling2D(2,2),
    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(3, activation='softmax')
])

model.summary()

# from keras.callbacks import EarlyStopping

# early_stopping = EarlyStopping(monitor='val_accuracy', patience=2, mode='max', verbose=1)

model.compile(optimizer=RMSprop(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])

history = model.fit(
    train_generator,
    steps_per_epoch=10,
    validation_data=validation_generator,
    validation_steps=10,
    epochs=100,
    verbose=1
    # callbacks=[early_stopping]
)

model.evaluate(validation_generator)

import matplotlib.pyplot as plt
import seaborn as sns

accuracy = history.history['accuracy']
val_accuracy = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']
epochs = range(1, len(accuracy) + 1)

sns.set(style='whitegrid')

plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(epochs, accuracy, 'bo', label='Training Accuracy')
plt.plot(epochs, val_accuracy, 'b', label='Validation Accuracy')
plt.title('Training and Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(epochs, loss, 'bo', label='Training Loss')
plt.plot(epochs, val_loss, 'b', label='Validation Loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

plt.tight_layout()
plt.show()

def predict_uploaded_image(model, img_path):
    img = image.load_img(img_path, target_size=(224, 224))
    img = image.img_to_array(img)
    img = np.expand_dims(img, axis=0)
    img /= 255.0

    result = model.predict(img)
    class_index = np.argmax(result)

    return class_index

uploaded = files.upload()

for filename in uploaded.keys():
    img_path = filename
    class_index = predict_uploaded_image(model, img_path)

    if class_index == 0:
        print("Gambar adalah kertas")
    elif class_index == 1:
        print("Gambar adalah batu")
    else:
        print("Gambar adalah gunting")

    display(Image(img_path))